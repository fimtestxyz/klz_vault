- - 计算机视觉领域背景与问题
        
        - 近十年深度学习推动计算机视觉显著发展（2012年起系统表征能力因深度模型、计算力、大规模标注数据提升）
            
        - 矛盾：计算力与模型复杂度持续增长（如AlexNet到ResNet），但数据集规模未相应扩大（ImageNet仍为100万张）
            
        - 核心疑问：数据量扩大（10倍、100倍、300倍）对模型精度的影响（是否翻倍、是否趋于平稳）
            
    - 研究相关介绍
        
        - 研究论文：《Revisiting Unreasonable Effectiveness of Data in Deep Learning Era》
            
        - 研究目标：探索数据与深度学习的关系（噪声标签数据对表征学习的影响、数据与视觉任务性能的关系、基于大规模学习的最优模型）
            
        - 关键数据集：JFT-300M（谷歌内部3亿张图像，18291个类别，超10亿标签，约3.75亿标签经算法筛选提升精度，仍有20%标签噪声，无法估算标签召回率）
            
    - 实验结果发现
        
        - 大规模数据助力表征学习：提升各类视觉任务性能，表明构建大规模视觉预训练数据集的重要性，且数据规模可压制标签噪声
            
        - 性能与数据量呈对数关系：视觉任务性能随表征学习所用训练数据量的增加呈对数增长（以JFT-300M不同子集预训练的目标检测性能为例）
            
        - 模型容量至关重要：需更高容量（更深）模型充分利用3亿张图像（如ResNet-152在COCO目标检测基准上的增益高于ResNet-50）
            
        - 刷新基准结果：在多个基准上取得新最优结果（如COCO检测基准单模型AP达37.4，高于此前34.3）
            
    - 研究局限性与未来方向
        
        - 局限性：训练机制、学习计划和参数基于ImageNet经验，未搜索最优超参数，报告的性能可能低估数据实际影响；未关注任务特定数据（如边界框数量对性能的影响）
            
        - 未来方向：聚焦获取大规模任务特定数据；社区应探索更大规模（10亿+图像）数据集下模型的性能提升情况
            
    - 研究贡献者与致谢
        
        - 核心贡献者：Chen Sun、Abhinav Shrivastava、Saurabh Singh、Abhinav Gupta
            
        - 致谢对象：谷歌图像理解和扩展团队（构建JFT数据集）、Tom Duerig等个人、VALE团队（提供API及讨论支持）