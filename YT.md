具身智能会是2025年最大的“泡沫”吗？今年，机器人似乎突然从只会走路发展到能快速学会做家务、跑步、打篮球、踢足球、打乒乓球、跳舞、练功夫等等。这种进步令人惊叹。我听说中国这方面的竞争也很激烈，而且优利特机器人公司即将上市。那么，人形机器人真的很快就要进到我家了吗？抱歉，我们可能要给你泼一盆冷水了。冷静下来。具身智能——看看这个词：第一部分是机器人的“硬件”，第二部分是它的“大脑”。这两个方向各自都有难点，而要将它们结合起来，同时还要兼顾精度、稳定性和商业化，就更具挑战性了。在这段视频中，我们采访了硅谷一些最知名的机器人公司，参观了几个尖端实验室，并与行业领袖探讨了机器人行业究竟是资本投机泡沫，还是真正的技术突破。2025年，人形机器人行业发生了一些令人震惊的事情。年初，优利特机器人公司（Unitree Robotics）突然发布了售价5900美元的R1人形机器人。就在一年前，业内普遍认为人形机器人的最低成本在2万至3万美元之间。优利特的举动彻底颠覆了整个行业的价格预期。随后，人工智能的估值从2024年的26亿美元飙升至390亿美元，增长了15倍。投资者名单堪称科技界的奥斯卡：微软、OpenAI、英伟达、贝佐斯、英特尔、三星等等。资本市场正疯狂押注，然而与此同时，特斯拉雄心勃勃地承诺生产5000辆Optimus车型，但实际上只组装了约1000辆就被迫暂停生产并进行重新设计。马斯克曾夸口说“特斯拉80%的价值将来自Optimus”，但现实却与之形成鲜明对比，显得颇为尴尬。这种反差令人费解。具身智能究竟发展到了什么阶段？本视频将从算法、硬件、数据和资本的角度探讨这个问题……我们将深入研究关键领域，包括主要参与者的战略，并提供详细的分析。结论是，到2025年，具身智能将从“先锋演示”阶段过渡到更加务实的“谨慎探索与发展”阶段。业界正在认清现实，不再空谈宏伟承诺，而是在真实场景中验证其能力的极限。演示视频依然令人印象深刻，但实际应用却变得更加谨慎。技术突破固然令人兴奋，但商业化的每一步都离不开成本核算。好消息是，这种转变恰恰表明机器人正变得越来越实用。接下来，我们将详细解读具身智能。在探讨行业现状之前，让我们先明确一下具身智能的定义。如果说 ChatGPT 是“会说话的”人工智能，那么具身智能就是“面向行动的”人工智能。它的核心是 VLA（车辆自动化）。视觉-语言-动作 (VLAA) 模型将这三个要素整合到一个神经网络中：视觉（感知当前场景）、语言（理解任务目标和常识）以及动作（输出特定的控制指令）。简而言之，它具备三种能力：理解环境、理解指令和执行动作。这与传统机器人有何不同？举例来说，传统的工业机器人就像只能记住固定台词的演员；你对它们进行编程，它们就按部就班地执行剧本。然而，具身智能机器人更像是能够即兴发挥的演员；它们可以理解环境变化并做出自主决策。例如，如果你让机器人折叠毛巾，传统的机器人每次都必须将毛巾放在完全相同的位置。但具身智能机器人可以识别出毛巾是否起皱或歪斜，调整其运动轨迹，并仍然能够正确地折叠毛巾。Dyna Robotics 是一家炙手可热的硅谷具身智能公司，成立于一年前，已在 A 轮融资中筹集了 1.2 亿美元，公司估值达到 6 亿美元。投资者包括英伟达。“折叠毛巾”任务正是 Dyna 一举成名的演示。简而言之，VLA 以大规模模型域 VLM 为基础，但最终输出的是将 VLM 的结果转换为机器人领域可用的动作。直观地说，一个动作可以转化为指令，例如将机械臂移动到特定的坐标点。对VLA最常见的批评是：为什么我们需要语言（Language）？因为许多传统的机器人算法纯粹基于视觉，但仔细想想，你的大脑实际上会产生类似视觉的信息。
语言的作用在于告诉你，在长期任务中，应该先做什么，后做什么。视觉算法（VLA）的作用在于，对于一​​些非常复杂的任务，它可以从训练过的大型语言模型中学习到大量的逻辑。例如，如果你想喝水，你需要找到一个杯子或瓶子。大型语言模型可以直接告诉你这一点。使用视觉算法（VLA）的主要目的是更好地结合语言和视觉。否则，如果你只有视觉，你所能完成的任务可能都是短期的。你无法完成任何需要推理的长期任务。这就是我们如此重视引入语言的主要原因。这是一个质的飞跃。机器人不再仅仅是执行固定程序的机械臂，而是可以通过视觉、语言和动作的结合来理解和规划。具身智能，即自适应智能体，并不是一个新概念。为什么它会在2025年突然爆发式增长？主要有三个因素。首先，大规模模型本身已经成熟。无论是 OpenAI 还是其他公司，近期大规模模型的改进更多是渐进式的，而非像 GPT-3.5 到 GPT-4 那样的飞跃式发展。在此背景下，大规模模型的整体能力趋于稳定，足以作为具身智能系统的可靠基础。ChatGPT 能力层证明，大型语言模型能够理解复杂的指令，并进行规划和推理。这种能力可以转移到机器人身上。例如，如果你说“给我做早餐”，它可以规划出一个多步骤序列，比如“先拿鸡蛋，然后打鸡蛋，最后煎鸡蛋”。其次，计算能力的价格大幅下降。整体计算能力水平持续提升。随着芯片制造商不断推出性能更强的新一代芯片，同等计算能力的单位成本呈现长期下降趋势。通常情况下，每隔几年，获取相同计算能力的成本就会降至之前的一半。2023 年，租用一块 NVIDIA H100 GPU 仍然价格不菲。云计算算力的价格战愈演愈烈，大幅降低了大型模型的训练成本。曾经只有龙头企业才能负担得起的“游戏”，如今初创企业也能轻松涉足。其次，硬件供应链日趋成熟，机器人硬件组件的整体成熟度也相对较高。尤其是在过去一年人形机器人热潮的推动下，大量资金和工程资源被投入到包括电机、减速器等核心组件的研发中，这带来了技术的持续成熟和成本的不断降低。玉树已将价格直接降至5900美元。此前，业内普遍认为2万至3万美元的价格区间足以满足大规模生产的需求。成本曲线的急剧下降使得商业化不再是遥不可及的梦想。这三大因素共同推动了具身智能从实验室走向商业化，但这并非盲目乐观，而是基于技术成熟度的理性判断。那么，具身智能目前具备哪些能力，又能做些什么呢？我们先来谈谈它能做什么。目前，具身智能已经在工业和商业领域得到实际应用。折叠毛巾和衣物听起来很简单，但Dyna公司的机器人可以在24小时内折叠700条毛巾，成功率高达99.4%。这在酒店和洗衣店已经是一项实实在在的生产力提升。此外，它们的基础模型还包含各种场景数据，例如切菜切果、准备食物、早餐清洁和物流分拣。在宝马集团的工厂里，Figure公司的机器人正在进行简单的组装和物料搬运工作。Agility Robotics公司的Digit机器人则在仓储和物流场景中搬运箱子。1X公司也将为瑞典巨头EQT公司交付多达1万台设备。Neo人形机器人主要应用于制造、仓储和物流等工业场景。更不用说，亚马逊已经部署了100万台专用机器人，几乎超过了其156万名员工的总和。这些并非演示，而是真实运行的商业项目。这是“理性进步”——追求的不是全能，而是实用性。那么，目前领先企业还有哪些任务是无法完成的呢？例如，中等难度的任务，比如做早餐。这是一项“长期任务”，需要规划多个步骤：准备食材、切菜、装盘、开火、翻炒。每个步骤都需要精准执行和力度控制——避免压碎鸡蛋或在切菜时割伤手。Dyna 的最新演示已经证明了它能够处理这项长期任务——制作早餐，而 Figure 也展示了两个机器人协同工作的场景。
语言的作用在于告诉你，在长期任务中，应该先做什么，后做什么。视觉算法（VLA）的作用在于，对于一​​些非常复杂的任务，它可以从训练过的大型语言模型中学习到大量的逻辑。例如，如果你想喝水，你需要找到一个杯子或瓶子。大型语言模型可以直接告诉你这一点。使用视觉算法（VLA）的主要目的是更好地结合语言和视觉。否则，如果你只有视觉，你所能完成的任务可能都是短期的。你无法完成任何需要推理的长期任务。这就是我们如此重视引入语言的主要原因。这是一个质的飞跃。机器人不再仅仅是执行固定程序的机械臂，而是可以通过视觉、语言和动作的结合来理解和规划。具身智能，即自适应智能体，并不是一个新概念。为什么它会在2025年突然爆发式增长？主要有三个因素。首先，大规模模型本身已经成熟。无论是 OpenAI 还是其他公司，近期大规模模型的改进更多是渐进式的，而非像 GPT-3.5 到 GPT-4 那样的飞跃式发展。在此背景下，大规模模型的整体能力趋于稳定，足以作为具身智能系统的可靠基础。ChatGPT 能力层证明，大型语言模型能够理解复杂的指令，并进行规划和推理。这种能力可以转移到机器人身上。例如，如果你说“给我做早餐”，它可以规划出一个多步骤序列，比如“先拿鸡蛋，然后打鸡蛋，最后煎鸡蛋”。其次，计算能力的价格大幅下降。整体计算能力水平持续提升。随着芯片制造商不断推出性能更强的新一代芯片，同等计算能力的单位成本呈现长期下降趋势。通常情况下，每隔几年，获取相同计算能力的成本就会降至之前的一半。2023 年，租用一块 NVIDIA H100 GPU 仍然价格不菲。云计算算力的价格战愈演愈烈，大幅降低了大型模型的训练成本。曾经只有龙头企业才能负担得起的“游戏”，如今初创企业也能轻松涉足。其次，硬件供应链日趋成熟，机器人硬件组件的整体成熟度也相对较高。尤其是在过去一年人形机器人热潮的推动下，大量资金和工程资源被投入到包括电机、减速器等核心组件的研发中，这带来了技术的持续成熟和成本的不断降低。玉树已将价格直接降至5900美元。此前，业内普遍认为2万至3万美元的价格区间足以满足大规模生产的需求。成本曲线的急剧下降使得商业化不再是遥不可及的梦想。这三大因素共同推动了具身智能从实验室走向商业化，但这并非盲目乐观，而是基于技术成熟度的理性判断。那么，具身智能目前具备哪些能力，又能做些什么呢？我们先来谈谈它能做什么。目前，具身智能已经在工业和商业领域得到实际应用。折叠毛巾和衣物听起来很简单，但Dyna公司的机器人可以在24小时内折叠700条毛巾，成功率高达99.4%。这在酒店和洗衣店已经是一项实实在在的生产力提升。此外，它们的基础模型还包含各种场景数据，例如切菜切果、准备食物、早餐清洁和物流分拣。在宝马集团的工厂里，Figure公司的机器人正在进行简单的组装和物料搬运工作。Agility Robotics公司的Digit机器人则在仓储和物流场景中搬运箱子。1X公司也将为瑞典巨头EQT公司交付多达1万台设备。Neo人形机器人主要应用于制造、仓储和物流等工业场景。更不用说，亚马逊已经部署了100万台专用机器人，几乎超过了其156万名员工的总和。这些并非演示，而是真实运行的商业项目。这是“理性进步”——追求的不是全能，而是实用性。那么，目前领先企业还有哪些任务是无法完成的呢？例如，中等难度的任务，比如做早餐。这是一项“长期任务”，需要规划多个步骤：准备食材、切菜、装盘、开火、翻炒。每个步骤都需要精准执行和力度控制——避免压碎鸡蛋或在切菜时割伤手。Dyna 的最新演示已经证明了它能够处理这项长期任务——制作早餐，而 Figure 也展示了两个机器人协同工作的场景。
跨机器人泛化能力（物理层面）。Intelligence 的 π0 模型和开源的 OpenVLA 模型可以控制多个不同的机器人。同一个模型或策略可以有效地应用于形状和硬件配置不同的机器人，而无需为每个机器人重新训练。这被称为跨机器人泛化能力，非常重要。以前，每个机器人都需要单独训练模型，成本很高。现在，单个模型可以适配多个机器人，并且可以共享数据，从而显著降低成本。然而，技术上的难点也显而易见。不同的机器人在运动空间、臂长和关节数量方面存在巨大差异。那么，单个模型如何控制它们呢？这种在完全陌生的环境中工作的能力并非完美无缺，但已经是一个显著的进步。最终的突破是多机器人协作。图示展示了如何使用单个神经网络来协调两个机器人的协作。创新之处在于，它利用单个神经网络控制整个上半身的35个自由度，同时还能控制两个机器人协同工作。这听起来很简单，但实际上却非常困难。两个机器人需要相互协作，并且时间、力和位置都需要精确同步。这项技术在未来的工厂场景中将非常有用，但目前仍处于早期验证阶段。因此，这些技术突破都不是颠覆性的，但每一项都取得了稳步进展。这正是2025年的特征：不再追求炫目的演示，而是朝着可验证、可量化和可复现的方向稳步前进。我在开头提到过，我想给这泼一盆冷水，因为具身智能领域仍然有很多核心问题需要解决。技术突破固然重要，但该行业仍然面临着几个重大挑战。清晰地认识到这些挑战正是“理性进步”的先决条件，也正是这一点将具身智能推向了爆发式增长的前夜。首先是数据难题。ChatGPT 的训练使用了数万亿个词元，实际上是将整个互联网的文本都输入其中，但机器人运行数据却极其稀缺。谷歌花了 17 个月的时间训练其 RT-2 模型，在一个真实的厨房中收集了 13 万个数据点，但其泛化能力仍然有限。为什么机器人数据如此难以收集？因为它需要真正的机器人在真实环境中运行。每一条数据都需要花费金钱和时间，而且任何错误都可能损坏设备。这与可以通过网络爬虫获取的文本数据截然不同。因此，大多数机器人基础模型仍然依赖少量真实数据加上大量模拟合成数据来强化学习或采用自监督方法。接下来，我们采访了硅谷一家专注于机器人大脑领域的明星初创公司 Physical。一位情报研究人员做出了一个大胆的预测：假设人的一生大约是100年，粗略估计，那就是大约100万小时。我认为，就我所知，或者说在公开信息范围内，没有人拥有100万小时的数据集。我推测，只有当我们获得相当于100万小时人生实际经验的数据时，我们才能开始探索。如果数据是机器人的“石油”，那么这口井尚未被开采。第二个问题是虚拟世界和现实世界之间的差距。在虚拟世界中训练机器人成本低廉，可以同时运行数万台模拟器。然而，虚拟世界永远不是现实世界。就像擅长赛车游戏并不意味着你真的能驾驶F1赛车一样。现实世界的摩擦力、柔软度和光照变化过于复杂；模拟只能重现部分真实的物理特性。其余的问题正是机器人从模拟器到现实世界“文化冲击”的根源所在。英伟达的Genesis和Isaac模拟器正努力缩小这一差距，但彻底消除它还需要时间。第三个尚未解决的问题被称为具身性。人手有27个关节，可以感知压力、温度和纹理，而机器人灵巧的手通常只有15-22个关节。传感器的精度也不如人手。即使机器人完美地模仿了人类的运动模式，结果也会有所不同。人可以轻轻地拿起一个鸡蛋，但机器人可能只需稍加用力就能把它捏碎。首先，如果想要很好地实现能力转移，人手和机器人手必须非常相似。这就是为什么现在许多人都在致力于研发高度灵巧、能够高度模拟人类自由度的机械手——这本身就非常困难。其次，即使非常接近，也无法完全相同。因此，机器人数据和人类数据之间仍然存在差距，我们称之为具身性。
具身认知差距。这一差距被学术界和工业界普遍认为是一个难以解决的问题，导致数据传输效率低下。试想一下，收集了大量数据；如果只有30%或50%的数据可用，那么总数据量就需要乘以概率因子。这是一个限制，意味着特斯拉在使用来自YouTube的大量人类视频数据训练Optimus策略时面临着巨大的技术挑战。这就是为什么特斯拉在生产了1000台后停止生产并重新设计的原因。理想固然美好，但现实却残酷。第四个挑战是可靠性。如果GPT回答错误，用户可能只是一笑置之；但如果机器人犯错，它可能会损坏物品或伤人——这就是质的差别。具身智能必须达到极高的可靠性才能真正进入工厂和家庭；这一标准比大型语言模型要严格得多。第五个挑战是成本困境——一个先有鸡还是先有蛋的问题。目前，人形机器人的定价需要控制在2万美元左右才能在物流和其他应用场景中具有足够的吸引力。然而，降低价格需要大规模生产，而大规模生产又需要大订单，大订单又需要足够低的价格。这就形成了一个恶性循环：必须有人打破僵局，但这会不会引发价格战？要推动整个行业降低成本，就需要观察并认识到这些挑战。这并非悲观，而是理性，因为初创公司已经务实地认识到了这些瓶颈。具身智能正处于爆发式增长的边缘。最后，我们来谈谈具身智能领域的主要参与者以及他们选择的发展路径。面对这些挑战，不同的公司选择了不同的道路。特斯拉和Figure就是其中之一。他们的策略是将硬件和软件集成起来，创建一个数据闭环。特斯拉利用其积累的FSD自动驾驶技术，将视觉感知和路径规划能力转移到Optimus上。它还可以从工厂生产线收集数据。前工程总监米兰·科瓦奇直言不讳地说：“我们只是从轮式机器人过渡到腿式机器人。”然而，现实远比预期复杂。5000台机器人的目标仅完成了五分之一，重新设计也不得不中止。这表明，即使是像特斯拉这样的巨头也必须面对实体化方面的挑战。Figure在与OpenAI“分道扬镳”后，独立开发了Helix模型，并掌控了自己的技术路线图，这表明他们确实具备技术能力。估值增长15倍也证明了资本市场对这条道路的认可。然而，他们目前仅商业化部署了几十台设备。演示令人印象深刻，但规模化仍在进行中。第二组包括我们刚才提到的Physical Intelligence和Skild。与许多同时投资硬件的机器人初创公司不同，这些公司优先考虑模型驱动的跨平台适应性。Physical Intelligence的π0模型不依赖于特定硬件，可以适应多种机器人。他们的逻辑是先强化模型的能力，然后再选择最佳的硬件解决方案。另一家公司是 Skild AI，这是一家专注于构建基础机器人模型的软件公司。Skild AI 的核心方向也是创建一个独立于特定机器人形态的通用基础模型，该模型能够适应不同的机器人平台和应用场景。今年 7 月，Skild AI 发布了其通用机器人系统 Skild Brain，并公开展示了其执行诸如拾取餐具和爬楼梯等任务的能力。最近，软银和英伟达计划向其投资 10 亿美元，使其估值达到 140 亿美元。第三类是专注于生态系统的平台。英伟达提供模拟器和计算能力基础设施，推出了 GR00T。N1 是开源的，但用户必须使用整个英伟达生态系统才能使用它。另一方面，谷歌持续投资学术研究。RT 系列模型影响了整个学术界。它们为整个行业提供了“水、电、气”。谁能制定行业标准，谁就能掌控生态系统。三条路径都在发展，没有哪一条路径占据绝对优势。大家都在尝试、迭代和调整。回到最初的问题，具身智能是泡沫还是未来？答案是，到2025年，具身智能将从“开拓性亮相”转向“理性发展”。从技术层面来说，大型模型与机器人的结合已经过测试，但远未成熟。数据、泛化能力和可靠性等核心问题尚未解决。如果用“GPT时刻”来类比，Robot CTO 王昊认为我们目前正处于GPT-2阶段。
我认为我们现在处于 GPT-2 阶段。事实上，我们基本已经知道，规模化是唯一可靠的途径。现阶段的关键在于疯狂地积累数据，扩展模型，并构建实际应用的基础设施。因此，我预测在未来一到两年内，我们可以完全达到 GPT-3 的水平。请注意，是 GPT-3，而不是 GPT-4。这是一个直接的评估。研究人员已经看到了规模化带来的改进，这使得发展路径和目标更加清晰明确。在商业方面，试点项目正在工业环境中启动，应用案例涵盖仓储、制造和服务行业。然而，大规模商业化可能还需要两到三年时间。我们的目标是至少在明年实现商业场景的大规模部署。至于家庭使用，我们将稍后考虑。因此，这个时间表应该不会太远，大概在一到两年内。就投资而言，既存在泡沫，也存在机遇。一些公司估值飙升，一些公司暂停生产，还有一些公司在耗尽现金后破产。（开源机器人公司K-Scale Labs）未能获得融资而破产；而Figure AI则资金充裕。这两种极端情况同时存在，表明市场存在分化。尽管具身智能的长期趋势稳定，但短期波动剧烈。具身智能的首个“杀手级应用”会是什么？可能是家务、仓储物流，或是餐厅清洁服务。无论具体应用场景如何，行业巨头们已经开始行动。具身智能不再是“是否会发生”的问题，而是“何时会发生”的问题。2025年，我们将站在这场革命的起点。行业不再仅仅展示炫酷的演示，而是开始对技术进行实际验证，完善产品，并寻找应用场景。特斯拉的停产并非失败，而是为了寻找更可靠的路径而进行的重新设计。Figure AI 估值飙升并非仅仅是资本投机，而是他们所取得的切实成果，例如 Helix。Dyna 从折叠毛巾起家并非视野狭隘，而是数据积累和飞轮效应的体现，从而培养模型学习能力。智能平台的一部分 π0 是开源的，但这并不意味着它不够开放；相反，它体现了在商业利益和技术共享之间寻求平衡的重要性。这种在现有基础上的稳步改进，正是行业走向成熟的标志。到 2025 年，具身智能行业将从“空中楼阁”发展到“撸起袖子加油干”。而这块“蛋糕”正在逐步稳步地变成现实。感谢您收看本期“硅谷 101”。我是联合创始人陈倩，也感谢大家在2025年的支持和陪伴。希望2026年我们能创作出更多精彩的内容。下个视频见！拜拜！

- - 计算机视觉领域背景与问题
        
        - 近十年深度学习推动计算机视觉显著发展（2012年起系统表征能力因深度模型、计算力、大规模标注数据提升）
            
        - 矛盾：计算力与模型复杂度持续增长（如AlexNet到ResNet），但数据集规模未相应扩大（ImageNet仍为100万张）
            
        - 核心疑问：数据量扩大（10倍、100倍、300倍）对模型精度的影响（是否翻倍、是否趋于平稳）
            
    - 研究相关介绍
        
        - 研究论文：《Revisiting Unreasonable Effectiveness of Data in Deep Learning Era》
            
        - 研究目标：探索数据与深度学习的关系（噪声标签数据对表征学习的影响、数据与视觉任务性能的关系、基于大规模学习的最优模型）
            
        - 关键数据集：JFT-300M（谷歌内部3亿张图像，18291个类别，超10亿标签，约3.75亿标签经算法筛选提升精度，仍有20%标签噪声，无法估算标签召回率）
            
    - 实验结果发现
        
        - 大规模数据助力表征学习：提升各类视觉任务性能，表明构建大规模视觉预训练数据集的重要性，且数据规模可压制标签噪声
            
        - 性能与数据量呈对数关系：视觉任务性能随表征学习所用训练数据量的增加呈对数增长（以JFT-300M不同子集预训练的目标检测性能为例）
            
        - 模型容量至关重要：需更高容量（更深）模型充分利用3亿张图像（如ResNet-152在COCO目标检测基准上的增益高于ResNet-50）
            
        - 刷新基准结果：在多个基准上取得新最优结果（如COCO检测基准单模型AP达37.4，高于此前34.3）
            
    - 研究局限性与未来方向
        
        - 局限性：训练机制、学习计划和参数基于ImageNet经验，未搜索最优超参数，报告的性能可能低估数据实际影响；未关注任务特定数据（如边界框数量对性能的影响）
            
        - 未来方向：聚焦获取大规模任务特定数据；社区应探索更大规模（10亿+图像）数据集下模型的性能提升情况
            
    - 研究贡献者与致谢
        
        - 核心贡献者：Chen Sun、Abhinav Shrivastava、Saurabh Singh、Abhinav Gupta
            
        - 致谢对象：谷歌图像理解和扩展团队（构建JFT数据集）、Tom Duerig等个人、VALE团队（提供API及讨论支持）