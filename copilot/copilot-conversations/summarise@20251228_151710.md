---
epoch: 1766906230010
modelKey: "qwen/qwen2.5-vl-7b|lm-studio"
topic: "Summarize Requested"


tags:
  - copilot-conversation
---

**user**: summarise 
[Context: Notes: Big Boss behind.md]
[Timestamp: 2025/12/28 15:17:10]

**ai**: 
<errorChunk>Trying to keep the first 7230 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input</errorChunk>
[Timestamp: 2025/12/28 15:17:17]

**user**: summarise it
[Context: Notes: Big Boss behind.md]
[Timestamp: 2025/12/28 15:17:36]

**ai**: 
<errorChunk>Trying to keep the first 6423 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input</errorChunk>
[Timestamp: 2025/12/28 15:17:36]