---
epoch: 1766582785660
modelKey: "qwen/qwen2.5-vl-7b|lm-studio"
topic: "Model Loading Error Summary"


tags:
  - copilot-conversation
---

**user**: summarise 
[Context: Notes: 00-Inbox/YT - Why everyone HATES GPT-5 (and how to fix it).md]
[Timestamp: 2025/12/24 21:26:25]

**ai**: 
<errorChunk>Connection error.
more message: Request failed, status 404. {"error":{"message":"No models loaded. Please load a model in the developer page or use the `lms load` command.","type":"invalid_request_error","param":"model","code":"model_not_found"}}</errorChunk>
[Timestamp: 2025/12/24 21:26:35]

**user**: summarise 
[Context: Notes: 00-Inbox/YT - Why everyone HATES GPT-5 (and how to fix it).md]
[Timestamp: 2025/12/24 21:28:26]

**ai**: 
<errorChunk>Trying to keep the first 35872 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input</errorChunk>
[Timestamp: 2025/12/24 21:28:26]

**user**: summarise
[Context: Notes: 00-Inbox/YT - Why everyone HATES GPT-5 (and how to fix it).md]
[Timestamp: 2025/12/24 21:29:03]

**ai**: 
<errorChunk>Trying to keep the first 35872 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input</errorChunk>
[Timestamp: 2025/12/24 21:29:03]

**user**: summarise
[Context: Notes: 00-Inbox/YT - Why everyone HATES GPT-5 (and how to fix it).md]
[Timestamp: 2025/12/24 21:31:22]

**ai**: 
<errorChunk>Trying to keep the first 35872 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input</errorChunk>
[Timestamp: 2025/12/24 21:31:22]

**user**: summarise
[Context: Notes: 00-Inbox/YT - Why everyone HATES GPT-5 (and how to fix it).md]
[Timestamp: 2025/12/24 21:42:55]

**ai**: The video discusses user dissatisfaction with GPT-5, a new AI model from OpenAI. The key points mentioned are:

1. **Personality Shift**: Many users dislike the new personality of GPT-5 compared to previous models like GPT-40 and 40 Pro.
2. **Forced Migration/Deletion**: Users were frustrated that OpenAI deleted older, more preferred models overnight without a choice or recourse.
3. **GPT-5 Performance**: Users criticize GPT-5 for being worse than expected in various aspects such as math problems, coding capabilities, and overall performance compared to
<errorChunk>Reached context length of 36000 tokens, but this model does not currently support mid-generation context overflow because llama_memory_can_shift is 0. Try reloading with a larger context length or shortening the prompt/chat.</errorChunk>
[Timestamp: 2025/12/24 21:47:36]

**user**: summarise the key user feedback on GPT5
[Context: Notes: 00-Inbox/YT - Why everyone HATES GPT-5 (and how to fix it).md]
[Timestamp: 2025/12/24 21:52:44]