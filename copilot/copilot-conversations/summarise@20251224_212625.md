---
epoch: 1766582785660
modelKey: "qwen/qwen2.5-vl-7b|lm-studio"
topic: "Model Loading Error Summary"


tags:
  - copilot-conversation
---

**user**: summarise 
[Context: Notes: 00-Inbox/YT - Why everyone HATES GPT-5 (and how to fix it).md]
[Timestamp: 2025/12/24 21:26:25]

**ai**: 
<errorChunk>Connection error.
more message: Request failed, status 404. {"error":{"message":"No models loaded. Please load a model in the developer page or use the `lms load` command.","type":"invalid_request_error","param":"model","code":"model_not_found"}}</errorChunk>
[Timestamp: 2025/12/24 21:26:35]

**user**: summarise 
[Context: Notes: 00-Inbox/YT - Why everyone HATES GPT-5 (and how to fix it).md]
[Timestamp: 2025/12/24 21:28:26]

**ai**: 
<errorChunk>Trying to keep the first 35872 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input</errorChunk>
[Timestamp: 2025/12/24 21:28:26]

**user**: summarise
[Context: Notes: 00-Inbox/YT - Why everyone HATES GPT-5 (and how to fix it).md]
[Timestamp: 2025/12/24 21:29:03]

**ai**: 
<errorChunk>Trying to keep the first 35872 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input</errorChunk>
[Timestamp: 2025/12/24 21:29:03]

**user**: summarise
[Context: Notes: 00-Inbox/YT - Why everyone HATES GPT-5 (and how to fix it).md]
[Timestamp: 2025/12/24 21:31:22]

**ai**: 
<errorChunk>Trying to keep the first 35872 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input</errorChunk>
[Timestamp: 2025/12/24 21:31:22]

**user**: summarise
[Context: Notes: 00-Inbox/YT - Why everyone HATES GPT-5 (and how to fix it).md]
[Timestamp: 2025/12/24 21:42:55]

**ai**: The video discusses user dissatisfaction with GPT-5, a new AI model from OpenAI. The key points mentioned are:

1. **Personality Shift**: Many users dislike the new personality of GPT-5 compared to previous models like GPT-40 and 40 Pro.
2. **Forced Migration/Deletion**: Users were frustrated that OpenAI deleted older, more preferred models overnight without a choice or recourse.
3. **GPT-5 Performance**: Users criticize GPT-5 for being worse than expected in various aspects such as math problems, coding capabilities, and overall performance compared to
<errorChunk>Reached context length of 36000 tokens, but this model does not currently support mid-generation context overflow because llama_memory_can_shift is 0. Try reloading with a larger context length or shortening the prompt/chat.</errorChunk>
[Timestamp: 2025/12/24 21:47:36]

**user**: summarise the key user feedback on GPT5
[Context: Notes: 00-Inbox/YT - Why everyone HATES GPT-5 (and how to fix it).md]
[Timestamp: 2025/12/24 21:52:44]

**ai**: The key user feedback on GPT-5, as summarized from the provided context and video content, includes:

1. **Personality Shift**: Many users dislike the new personality of GPT-5 compared to previous models like GPT-40 and 40 Pro.
2. **Forced Migration/Deletion**: Users were frustrated that OpenAI deleted older, more preferred models overnight without a choice or recourse.
3. **GPT-5 Performance**:
   - Criticism for being worse than expected in various aspects such as math problems, coding capabilities, and overall performance compared to previous versions.
4. **Accuracy Issues**: Some users report that GPT-5 is less accurate and more prone to giving incorrect answers or recommendations.
5. **Coding Capabilities**: Users find that GPT-5 isn't as good at coding as the older models like Opus 4.1, Claude 03 Pro, and even GPT-40.
6. **Mathematical Problems**: GPT-5 struggles with simple math problems compared to previous versions of ChatGPT.
7. **Outdated Information**: Users report that GPT-5 sometimes provides outdated information or recommendations based on old data sources.

Overall, the feedback suggests a mixed experience where users are underwhelmed by some aspects but find other features impressive, hoping for improvements over time as OpenAI listens to user concerns and makes adjustments.
[Timestamp: 2025/12/24 21:54:43]

**user**: analyse this youtube video 
[Context: Notes: 00-Inbox/YT-2025年，人形机器人走到哪一步了？｜机器人系列｜具身智能年度盘点.md]
[Timestamp: 2025/12/24 22:01:26]

**ai**: The YouTube video titled "YT-2025年，人形机器人走到哪一步了？｜机器人系列｜具身智能年度盘点" discusses the progress and challenges in embodied intelligence, a field that integrates robotics with large language models. Here's an analysis of its key points:

### Key Points from the Video

1. **Introduction to Embodied Intelligence**:
   - Embodied intelligence is described as "action-oriented AI," which combines vision (seeing), language (understanding commands and common sense), and action (performing specific control commands).
   - It's a significant leap forward in robotics, where robots can understand their environment, comprehend tasks, and perform actions autonomously.

2. **Technological Breakthroughs**:
   - The video highlights three major technological advancements that have propelled embodied intelligence: 
     1. **Maturity of Large Language Models**: Improved capabilities of large language models (e.g., ChatGPT) provide a reliable foundation for embodied systems.
     2. **Declining Computing Power Costs**: Lower costs and improved computing power make it feasible to train larger models, which is crucial for embodied intelligence.
     3. **Mature Hardware Supply Chain**: Advanced hardware components like motors and reducers have been developed, reducing the cost of humanoid robots.

3. **Current Capabilities**:
   - Practical applications are already being seen in industrial scenarios: folding towels, chopping vegetables, preparing food, etc., with high success rates.
   - Examples include BMW Group's factories using Figure’s robots for simple assembly tasks and Agility Robotics' Digit moving boxes in warehouses.
   - Amazon has deployed over 1 million dedicated robots, indicating a significant shift towards commercial applications.

4. **Challenges and Limitations**:
   - **Data Difficulty**: Collecting real-world data is slow and expensive; synthetic data generated using simulators can help but faces limitations (e.g., it may not capture all complexities).
   - **Virtual vs Real World Gap**: Simulations are useful for training, but the real world presents unique challenges that robots must adapt to.
   - **Embodiment Gap**: Human hands have 27 joints and can sense pressure, temperature, and texture; robotic hands typically have fewer joints and less precise sensors. This gap limits the transfer of human-like abilities to robots.
   - **Reliability**: Robots need to achieve extremely high reliability in real-world applications, which is more stringent than for large language models.

5. **Industry Players**:
   - Companies like Tesla, Figure AI, Physical Intelligence, Skild AI are making strides by focusing on hardware-software integration and model-driven approaches.
   - Nvidia's simulators (Genesis and Isaac) aim to bridge the gap between virtual and real-world environments.
   - Google's RT series models have influenced academic research and industry standards.

6. **Future Prospects**:
   - Embodied intelligence is expected to transition from "pioneering debut" to "rational progress."
   - The industry faces significant challenges but is making steady progress, with pilot projects in industrial settings.
   - A killer application for embodied intelligence could be household chores or warehousing and logistics services.

### Conclusion
The video presents a balanced view of the current state and future prospects of embodied intelligence. It highlights both the technological advancements that have propelled this field forward and the significant challenges still to be overcome, such as data collection, generalization capabilities, reliability, and embodiment gaps. The industry is maturing, with practical applications already being implemented in various sectors, but it's not yet ready for widespread home use or fully autonomous robots.

### Recommendations
- **Further Research**: Explore how advancements in large language models (LLMs) can be better integrated into embodied systems.
- **Data Collection Strategies**: Develop more efficient and cost-effective methods to collect real-world data for training robots.
- **Simulation Enhancements**: Improve the fidelity of simulators to better reflect real-world conditions, reducing reliance on expensive physical testing.

This analysis should provide a comprehensive understanding of the current landscape and future directions in embodied intelligence.
[Timestamp: 2025/12/24 22:04:20]