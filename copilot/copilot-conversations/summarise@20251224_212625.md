---
epoch: 1766582785660
modelKey: "qwen/qwen2.5-vl-7b|lm-studio"
topic: "Model Loading Error Summary"


tags:
  - copilot-conversation
---

**user**: summarise 
[Context: Notes: 00-Inbox/YT - Why everyone HATES GPT-5 (and how to fix it).md]
[Timestamp: 2025/12/24 21:26:25]

**ai**: 
<errorChunk>Connection error.
more message: Request failed, status 404. {"error":{"message":"No models loaded. Please load a model in the developer page or use the `lms load` command.","type":"invalid_request_error","param":"model","code":"model_not_found"}}</errorChunk>
[Timestamp: 2025/12/24 21:26:35]

**user**: summarise 
[Context: Notes: 00-Inbox/YT - Why everyone HATES GPT-5 (and how to fix it).md]
[Timestamp: 2025/12/24 21:28:26]

**ai**: 
<errorChunk>Trying to keep the first 35872 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input</errorChunk>
[Timestamp: 2025/12/24 21:28:26]

**user**: summarise
[Context: Notes: 00-Inbox/YT - Why everyone HATES GPT-5 (and how to fix it).md]
[Timestamp: 2025/12/24 21:29:03]

**ai**: 
<errorChunk>Trying to keep the first 35872 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input</errorChunk>
[Timestamp: 2025/12/24 21:29:03]

**user**: summarise
[Context: Notes: 00-Inbox/YT - Why everyone HATES GPT-5 (and how to fix it).md]
[Timestamp: 2025/12/24 21:31:22]

**ai**: 
<errorChunk>Trying to keep the first 35872 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input</errorChunk>
[Timestamp: 2025/12/24 21:31:22]

**user**: summarise
[Context: Notes: 00-Inbox/YT - Why everyone HATES GPT-5 (and how to fix it).md]
[Timestamp: 2025/12/24 21:42:55]

**ai**: The video discusses user dissatisfaction with GPT-5, a new AI model from OpenAI. The key points mentioned are:

1. **Personality Shift**: Many users dislike the new personality of GPT-5 compared to previous models like GPT-40 and 40 Pro.
2. **Forced Migration/Deletion**: Users were frustrated that OpenAI deleted older, more preferred models overnight without a choice or recourse.
3. **GPT-5 Performance**: Users criticize GPT-5 for being worse than expected in various aspects such as math problems, coding capabilities, and overall performance compared to
<errorChunk>Reached context length of 36000 tokens, but this model does not currently support mid-generation context overflow because llama_memory_can_shift is 0. Try reloading with a larger context length or shortening the prompt/chat.</errorChunk>
[Timestamp: 2025/12/24 21:47:36]

**user**: summarise the key user feedback on GPT5
[Context: Notes: 00-Inbox/YT - Why everyone HATES GPT-5 (and how to fix it).md]
[Timestamp: 2025/12/24 21:52:44]

**ai**: The key user feedback on GPT-5, as summarized from the provided context and video content, includes:

1. **Personality Shift**: Many users dislike the new personality of GPT-5 compared to previous models like GPT-40 and 40 Pro.
2. **Forced Migration/Deletion**: Users were frustrated that OpenAI deleted older, more preferred models overnight without a choice or recourse.
3. **GPT-5 Performance**:
   - Criticism for being worse than expected in various aspects such as math problems, coding capabilities, and overall performance compared to previous versions.
4. **Accuracy Issues**: Some users report that GPT-5 is less accurate and more prone to giving incorrect answers or recommendations.
5. **Coding Capabilities**: Users find that GPT-5 isn't as good at coding as the older models like Opus 4.1, Claude 03 Pro, and even GPT-40.
6. **Mathematical Problems**: GPT-5 struggles with simple math problems compared to previous versions of ChatGPT.
7. **Outdated Information**: Users report that GPT-5 sometimes provides outdated information or recommendations based on old data sources.

Overall, the feedback suggests a mixed experience where users are underwhelmed by some aspects but find other features impressive, hoping for improvements over time as OpenAI listens to user concerns and makes adjustments.
[Timestamp: 2025/12/24 21:54:43]

**user**: analyse this youtube video 
[Context: Notes: 00-Inbox/YT-2025年，人形机器人走到哪一步了？｜机器人系列｜具身智能年度盘点.md]
[Timestamp: 2025/12/24 22:01:26]

**ai**: The YouTube video titled "YT-2025年，人形机器人走到哪一步了？｜机器人系列｜具身智能年度盘点" discusses the progress and challenges in embodied intelligence, a field that integrates robotics with large language models. Here's an analysis of its key points:

### Key Points from the Video

1. **Introduction to Embodied Intelligence**:
   - Embodied intelligence is described as "action-oriented AI," which combines vision (seeing), language (understanding commands and common sense), and action (performing specific control commands).
   - It's a significant leap forward in robotics, where robots can understand their environment, comprehend tasks, and perform actions autonomously.

2. **Technological Breakthroughs**:
   - The video highlights three major technological advancements that have propelled embodied intelligence: 
     1. **Maturity of Large Language Models**: Improved capabilities of large language models (e.g., ChatGPT) provide a reliable foundation for embodied systems.
     2. **Declining Computing Power Costs**: Lower costs and improved computing power make it feasible to train larger models, which is crucial for embodied intelligence.
     3. **Mature Hardware Supply Chain**: Advanced hardware components like motors and reducers have been developed, reducing the cost of humanoid robots.

3. **Current Capabilities**:
   - Practical applications are already being seen in industrial scenarios: folding towels, chopping vegetables, preparing food, etc., with high success rates.
   - Examples include BMW Group's factories using Figure’s robots for simple assembly tasks and Agility Robotics' Digit moving boxes in warehouses.
   - Amazon has deployed over 1 million dedicated robots, indicating a significant shift towards commercial applications.

4. **Challenges and Limitations**:
   - **Data Difficulty**: Collecting real-world data is slow and expensive; synthetic data generated using simulators can help but faces limitations (e.g., it may not capture all complexities).
   - **Virtual vs Real World Gap**: Simulations are useful for training, but the real world presents unique challenges that robots must adapt to.
   - **Embodiment Gap**: Human hands have 27 joints and can sense pressure, temperature, and texture; robotic hands typically have fewer joints and less precise sensors. This gap limits the transfer of human-like abilities to robots.
   - **Reliability**: Robots need to achieve extremely high reliability in real-world applications, which is more stringent than for large language models.

5. **Industry Players**:
   - Companies like Tesla, Figure AI, Physical Intelligence, Skild AI are making strides by focusing on hardware-software integration and model-driven approaches.
   - Nvidia's simulators (Genesis and Isaac) aim to bridge the gap between virtual and real-world environments.
   - Google's RT series models have influenced academic research and industry standards.

6. **Future Prospects**:
   - Embodied intelligence is expected to transition from "pioneering debut" to "rational progress."
   - The industry faces significant challenges but is making steady progress, with pilot projects in industrial settings.
   - A killer application for embodied intelligence could be household chores or warehousing and logistics services.

### Conclusion
The video presents a balanced view of the current state and future prospects of embodied intelligence. It highlights both the technological advancements that have propelled this field forward and the significant challenges still to be overcome, such as data collection, generalization capabilities, reliability, and embodiment gaps. The industry is maturing, with practical applications already being implemented in various sectors, but it's not yet ready for widespread home use or fully autonomous robots.

### Recommendations
- **Further Research**: Explore how advancements in large language models (LLMs) can be better integrated into embodied systems.
- **Data Collection Strategies**: Develop more efficient and cost-effective methods to collect real-world data for training robots.
- **Simulation Enhancements**: Improve the fidelity of simulators to better reflect real-world conditions, reducing reliance on expensive physical testing.

This analysis should provide a comprehensive understanding of the current landscape and future directions in embodied intelligence.
[Timestamp: 2025/12/24 22:04:20]

**user**: {activeNote} 分析全文
[Context: Notes: YT.md]
[Timestamp: 2025/12/24 22:09:19]

**ai**: ### 全文分析

#### 一、引言与背景介绍：
- **问题提出**：具身智能是否会成为2025年的最大泡沫？
- **现象描述**：机器人技术在短短几年内取得了显著进步，从简单的行走发展到能够做家务、跑步、打篮球等复杂任务。
- **市场反应**：中国也出现了激烈的竞争，优利特机器人即将上市。

#### 二、技术背景与挑战：
1. **硬件与软件结合**：
   - 大规模模型的成熟：大型语言模型（如ChatGPT）在理解复杂指令和进行规划推理方面表现出色。
   - 计算能力成本下降：云计算算力价格战使得大规模模型训练成本降低，初创企业也能参与其中。

2. **数据难题**：
   - 真实机器人运行数据稀缺。例如，谷歌花了17个月才在真实厨房中收集了13万个数据点。
   - 数据采集困难：需要真正的机器人在真实环境中运行，每条数据都需花费时间和金钱，并且错误可能损坏设备。

#### 三、技术突破与进展：
1. **架构创新**：
   - “System 1 + System 2”架构：将机器人分为“快思考”和“慢思考”，分别负责反射动作和复杂规划任务。
   - 案例分析：Figure AI的Helix模型展示了这种架构的成功应用。

2. **数据生成与利用**：
   - Nvidia通过模拟器生成大量操作轨迹，如780,000条轨迹在11小时内完成，相当于6500小时的人类演示数据。
   - 大规模语言模型（如GPT）的训练数据量庞大，但低质量数据也能训练出相对较好的模型。

3. **跨机器人泛化能力**：
   - Intelligence的π0模型和OpenVLA模型可以控制多个不同类型的机器人，提高了模型的通用性。

4. **多机器人协作**：
   - 单个神经网络协调两个机器人的合作。这种技术在工厂场景中非常有用，但目前仍处于验证阶段。

#### 四、行业现状与挑战：
1. **数据难题**：大规模真实数据采集困难。
2. **虚拟现实差距**：模拟器无法完全再现现实世界中的复杂物理特性。
3. **具身性问题**：机器人手的关节数量和精度远低于人类，导致动作模仿不准确。
4. **可靠性挑战**：机器人错误可能导致设备损坏或人员受伤。

#### 五、主要参与者与策略：
1. **特斯拉与Figure**：
   - 集成硬件软件，创建数据闭环。特斯拉利用FSD技术将视觉感知和路径规划能力转移到Optimus上。
2. **Physical Intelligence与Skild AI**：
   - 强调模型驱动的跨平台适应性，先强化模型能力再选择最佳硬件解决方案。

3. **Nvidia与Google**：
   - Nvidia提供模拟器和计算基础设施；Google持续投资学术研究，影响整个行业标准制定。

#### 六、未来展望：
- **技术成熟度**：从GPT-2到GPT-3的过渡。
- **商业化进展**：预计两至三年内实现大规模部署。家庭使用可能稍后考虑。
- **市场分化**：既有公司估值飙升，也有暂停生产甚至破产的情况。

#### 七、总结与结论：
- 具身智能正从“开拓性亮相”转向“理性发展”，但仍面临诸多挑战。
- 技术进步和商业化进展需平衡数据积累、模型扩展和实际应用基础设施建设。
- 预计未来一到两年内，具身智能将取得显著进展。

### 总结
全文详细分析了2025年具身智能领域的技术发展与市场动态。尽管面临诸多挑战，如数据采集困难、虚拟现实差距等，但通过技术创新和策略调整，具身智能有望在未来几年实现突破性进展，并逐步商业化。
[Timestamp: 2025/12/24 22:12:14]

**user**: create excalidraw
[Context: Notes: 00-Inbox/Untitled.md]
[Timestamp: 2025/12/24 22:32:40]